{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\Documents\\GitHub\\Physio-Chatbot\\physioenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "load_dotenv(dotenv_path=r'C:\\Users\\ASUS\\Documents\\GitHub\\Physio-Chatbot\\.env')\n",
    "# CONFIGURING GENAI KEY\n",
    "genai.configure(api_key=\"AIzaSyBQYr-DYYiblGp4SwDGUgQ0oVN8lWlNgb4\")\n",
    "api_key=os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyBQYr-DYYiblGp4SwDGUgQ0oVN8lWlNgb4\n"
     ]
    }
   ],
   "source": [
    "print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = extract_text_from_pdf(r\"C:\\Users\\ASUS\\Documents\\GitHub\\Physio-Chatbot\\Sources\\Tidy's Physiotherapy.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# Function to split the extracted text into chunks\n",
    "def split_text_into_chunks(text):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_chunks=split_text_into_chunks(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0: Tidy's Physiotherapy\n",
      "Dedication\n",
      "To all the physiotherapy students, who have taught me so much.\n",
      "I tha\n",
      "Chunk 1: Manchester\n",
      "UK\n",
      "Honorary Research Fellow\n",
      "Wrightington Wigan and Leigh NHS Trust\n",
      "Wigan\n",
      "Lancashire\n",
      "UK\n",
      "B \n",
      "Chunk 2: or by any means, electronic, mechanical, photocopying, recording or otherwise, without either the pr\n",
      "Chunk 3: complete your request on-line via the Elsevier Science homepage (http://www.elsevier.com), by select\n",
      "Chunk 4: Notice\n",
      "Medical knowledge is constantly changing. Standard safety precautions must be followed, but a\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(splitted_chunks[:5]):\n",
    "    print(f\"Chunk {i}: {chunk[:100]}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gemini_embeddings(chunks):\n",
    "    embeddings = []\n",
    "    for chunk in chunks:\n",
    "        if chunk.strip():  # Ensure the chunk is not empty\n",
    "            response = genai.embed_content(\n",
    "                model=\"models/text-embedding-004\",  # Gemini Pro embedding model\n",
    "                content=chunk\n",
    "            )\n",
    "            \n",
    "            # Now we directly access 'embedding' as it contains the values directly\n",
    "            if isinstance(response, dict) and 'embedding' in response:\n",
    "                embeddings.append(response['embedding'])  # Append the embedding directly\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_chunks=generate_gemini_embeddings(splitted_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pcsk_587F7D_GW5VmUoxCvHN1LjaaU4idQXDaYJX6EJqbTQMjcTyds7rbPxDkHav8YJAqPDY7BM\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "load_dotenv(dotenv_path=r'C:\\Users\\ASUS\\Documents\\GitHub\\Physio-Chatbot\\.env')\n",
    "papi_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "print(papi_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=papi_key)\n",
    "\n",
    "index = pc.Index(\"physio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_embeddings_in_batches(text_chunks, embeddings, batch_size=100):\n",
    "    vectors = []\n",
    "    \n",
    "    for i, embedding in enumerate(embeddings):\n",
    "        # Create metadata for each chunk\n",
    "        metadata = {\"text\": text_chunks[i], \"source\": \"your_document_source\"}\n",
    "        vector = {\n",
    "            \"id\": f\"vec{i}\",  # Unique ID for each vector\n",
    "            \"values\": embedding,  # The embedding values\n",
    "            \"metadata\": metadata  # Metadata for the chunk\n",
    "        }\n",
    "        vectors.append(vector)\n",
    "        \n",
    "        # Batch upsert every `batch_size` chunks\n",
    "        if (i + 1) % batch_size == 0 or (i + 1) == len(embeddings):\n",
    "            index.upsert(vectors=vectors, namespace=\"ns1\")\n",
    "            vectors = []  # Clear the list after each batch\n",
    "\n",
    "# Call the function to upsert embeddings in batches\n",
    "upsert_embeddings_in_batches(splitted_chunks, embedded_chunks, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_query_embedding(query):\n",
    "    response = genai.embed_content(\n",
    "        model=\"models/text-embedding-004\",  # Gemini Pro embedding model\n",
    "        content=query\n",
    "    )\n",
    "    \n",
    "    # Extract and return the embedding from the response\n",
    "    if 'embedding' in response:\n",
    "        return response['embedding']\n",
    "    else:\n",
    "        raise ValueError(f\"Failed to generate embeddings for query: {query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_chunks(query_embedding):\n",
    "    # Search Pinecone index using the query embedding\n",
    "    query_response = index.query(\n",
    "        vector=query_embedding,\n",
    "        top_k=2,  # Adjust the number of top results you want\n",
    "        include_metadata=True  # Return metadata (e.g., source information) along with vectors\n",
    "    )\n",
    "    \n",
    "    # Extract relevant chunks from the Pinecone response\n",
    "    retrieved_chunks = [match['metadata']['text'] for match in query_response['matches']]\n",
    "    return retrieved_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "def query_and_retrieve(query):\n",
    "    # Step 1: Generate the embedding for the query\n",
    "    query_embedding = generate_query_embedding(query)\n",
    "    \n",
    "    # Step 2: Retrieve relevant chunks using the generated embedding\n",
    "    retrieved_texts = retrieve_relevant_chunks(query_embedding)\n",
    "    \n",
    "    # Step 3: Return the retrieved texts\n",
    "    return retrieved_texts\n",
    "\n",
    "# Example Usage\n",
    "query = \"What are the symptoms of anxiety?\"\n",
    "retrieved_texts = query_and_retrieve(query)\n",
    "\n",
    "print(retrieved_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to use Gemini Pro LLM to generate the final answer\n",
    "def generate_answer_with_gemini(query, retrieved_chunks):\n",
    "    # Combine the retrieved chunks into a single context\n",
    "    context = \"\\n\".join(retrieved_chunks)\n",
    "\n",
    "    # Crafting the prompt for PhysioBot\n",
    "    prompt = f\"\"\"\n",
    "    You are a PhysioBOT and you have been asked to provide information from the sources you have read : {context}\n",
    "    A user asks you: \"{query}\"\n",
    "    you must answer in a very friendly and informative way and you must provide the answer in detail and in a way that is easy to understand.\n",
    "    Based on your knowledge, you provide the following answer:\n",
    "    \"\"\"\n",
    "\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    response = model.generate_content([prompt])\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Embedding the query...\n",
      "Step 1 complete.\n",
      "Step 2: Retrieving relevant chunks from Pinecone...\n",
      "[]\n",
      "Step 2 complete.\n",
      "Step 3: Generating an answer using Gemini Pro LLM...\n",
      "Step 3 complete.\n",
      "\n",
      "Physio-BOT's Answer:\n",
      "**Quadriceps Strengthening Exercises:**\n",
      "\n",
      "* **Straight leg raises:** Lie on your back with your knees bent. Lift your right leg straight up, keeping your knee straight. Hold for 5 seconds, then slowly lower it down. Repeat 10-15 times.\n",
      "* **Wall slides:** Stand facing a wall with your feet shoulder-width apart. Place your hands on the wall at shoulder height and slide down the wall until your knees are bent at a 90-degree angle. Hold for 5 seconds, then slowly push yourself back up to the starting position. Repeat 10-15 times.\n",
      "* **Step-ups:** Stand facing a step or platform. Step onto the step with your right leg and then bring your left leg up to meet it. Step down with your left leg and then repeat with your right leg. Do 10-15 repetitions.\n",
      "\n",
      "**Patellar Mobilization Exercises:**\n",
      "\n",
      "* **Patellar glide:** Sit in a chair with your feet flat on the floor. Place your hands on your patella and gently slide it up and down your kneecap. Repeat 10-15 times.\n",
      "* **Patellar mobilization:** Sit in a chair with your feet flat on the floor. Place your hands on your patella and gently push it to the side. Hold for 5 seconds, then release. Repeat 10-15 times.\n",
      "\n",
      "**Other Beneficial Exercises:**\n",
      "\n",
      "* **Calf stretches:** Stand facing a wall with your feet shoulder-width apart. Step back with your right leg and bend your knee so that your heel is off the ground. Lean into the stretch until you feel it in your calf. Hold for 30 seconds, then release. Repeat with your left leg.\n",
      "* **Hamstring stretches:** Sit on the floor with your legs extended in front of you. Bend over at the waist and reach for your toes. Hold for 30 seconds, then release. Repeat 5-10 times.\n",
      "* **Core strengthening exercises:** Plank, side plank, and bird dog exercises can help to stabilize the knee joint.\n",
      "\n",
      "**Note:** It's important to consult with a healthcare professional before starting any exercise program, especially if you have pain. They can help you determine the best exercises for your individual needs and ensure that you are performing them correctly.\n"
     ]
    }
   ],
   "source": [
    "# Main function to handle user input and process the query through Physio-BOT\n",
    "def main():\n",
    "    # Prompt user for input\n",
    "    query = input(\"What would you like to ask Physio-BOT? \")\n",
    "\n",
    "    print(\"Step 1: Embedding the query...\")\n",
    "    # Step 1: Embed the query using Gemini Pro\n",
    "    query_embedding = generate_query_embedding(query)\n",
    "    print(\"Step 1 complete.\")\n",
    "\n",
    "    print(\"Step 2: Retrieving relevant chunks from Pinecone...\")\n",
    "    # Step 2: Retrieve relevant chunks from Pinecone based on query embedding\n",
    "    retrieved_chunks = retrieve_relevant_chunks(query_embedding)\n",
    "    print(retrieved_chunks)\n",
    "    print(\"Step 2 complete.\")\n",
    "\n",
    "    print(\"Step 3: Generating an answer using Gemini Pro LLM...\")\n",
    "    # Step 3: Generate an answer using Gemini Pro LLM with the retrieved chunks\n",
    "    answer = generate_answer_with_gemini(query, retrieved_chunks)\n",
    "    print(\"Step 3 complete.\")\n",
    "\n",
    "\n",
    "    # Display the final answer to the user\n",
    "    print(\"\\nPhysio-BOT's Answer:\")\n",
    "    print(answer)\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "physioenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
