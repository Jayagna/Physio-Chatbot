{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\Documents\\GitHub\\Physio-Chatbot\\physioenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "load_dotenv(dotenv_path=r'C:\\Users\\ASUS\\Documents\\GitHub\\Physio-Chatbot\\.env')\n",
    "# CONFIGURING GENAI KEY\n",
    "genai.configure(api_key=\"AIzaSyBQYr-DYYiblGp4SwDGUgQ0oVN8lWlNgb4\")\n",
    "api_key=os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyBQYr-DYYiblGp4SwDGUgQ0oVN8lWlNgb4\n"
     ]
    }
   ],
   "source": [
    "print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = extract_text_from_pdf(r\"C:\\Users\\ASUS\\Documents\\GitHub\\Physio-Chatbot\\Sources\\Tidy's Physiotherapy.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# Function to split the extracted text into chunks\n",
    "def split_text_into_chunks(text):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_chunks=split_text_into_chunks(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0: Tidy's Physiotherapy\n",
      "Dedication\n",
      "To all the physiotherapy students, who have taught me so much.\n",
      "I tha\n",
      "Chunk 1: Manchester\n",
      "UK\n",
      "Honorary Research Fellow\n",
      "Wrightington Wigan and Leigh NHS Trust\n",
      "Wigan\n",
      "Lancashire\n",
      "UK\n",
      "B \n",
      "Chunk 2: or by any means, electronic, mechanical, photocopying, recording or otherwise, without either the pr\n",
      "Chunk 3: complete your request on-line via the Elsevier Science homepage (http://www.elsevier.com), by select\n",
      "Chunk 4: Notice\n",
      "Medical knowledge is constantly changing. Standard safety precautions must be followed, but a\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(splitted_chunks[:5]):\n",
    "    print(f\"Chunk {i}: {chunk[:100]}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gemini_embeddings(chunks):\n",
    "    embeddings = []\n",
    "    for chunk in chunks:\n",
    "        if chunk.strip():  # Ensure the chunk is not empty\n",
    "            response = genai.embed_content(\n",
    "                model=\"models/text-embedding-004\",  # Gemini Pro embedding model\n",
    "                content=chunk\n",
    "            )\n",
    "            \n",
    "            # Now we directly access 'embedding' as it contains the values directly\n",
    "            if isinstance(response, dict) and 'embedding' in response:\n",
    "                embeddings.append(response['embedding'])  # Append the embedding directly\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_chunks=generate_gemini_embeddings(splitted_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pcsk_587F7D_GW5VmUoxCvHN1LjaaU4idQXDaYJX6EJqbTQMjcTyds7rbPxDkHav8YJAqPDY7BM\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "load_dotenv(dotenv_path=r'C:\\Users\\ASUS\\Documents\\GitHub\\Physio-Chatbot\\.env')\n",
    "papi_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "print(papi_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=papi_key)\n",
    "\n",
    "index = pc.Index(\"physio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_embeddings_in_batches(text_chunks, embeddings, batch_size=100):\n",
    "    vectors = []\n",
    "    \n",
    "    for i, embedding in enumerate(embeddings):\n",
    "        # Create metadata for each chunk\n",
    "        metadata = {\"text\": text_chunks[i], \"source\": \"your_document_source\"}\n",
    "        vector = {\n",
    "            \"id\": f\"vec{i}\",  # Unique ID for each vector\n",
    "            \"values\": embedding,  # The embedding values\n",
    "            \"metadata\": metadata  # Metadata for the chunk\n",
    "        }\n",
    "        vectors.append(vector)\n",
    "        \n",
    "        # Batch upsert every `batch_size` chunks\n",
    "        if (i + 1) % batch_size == 0 or (i + 1) == len(embeddings):\n",
    "            index.upsert(vectors=vectors, namespace=\"ns1\")\n",
    "            vectors = []  # Clear the list after each batch\n",
    "\n",
    "# Call the function to upsert embeddings in batches\n",
    "upsert_embeddings_in_batches(splitted_chunks, embedded_chunks, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_query_embedding(query):\n",
    "    response = genai.embed_content(\n",
    "        model=\"models/text-embedding-004\",  # Gemini Pro embedding model\n",
    "        content=query\n",
    "    )\n",
    "    \n",
    "    # Extract and return the embedding from the response\n",
    "    if 'embedding' in response:\n",
    "        return response['embedding']\n",
    "    else:\n",
    "        raise ValueError(f\"Failed to generate embeddings for query: {query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_chunks(query_embedding):\n",
    "    # Search Pinecone index using the query embedding\n",
    "    query_response = index.query(\n",
    "        vector=query_embedding,\n",
    "        top_k=2,  # Adjust the number of top results you want\n",
    "        include_metadata=True  # Return metadata (e.g., source information) along with vectors\n",
    "    )\n",
    "    \n",
    "    # Extract relevant chunks from the Pinecone response\n",
    "    retrieved_chunks = [match['metadata']['text'] for match in query_response['matches']]\n",
    "    return retrieved_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to use Gemini Pro LLM to generate the final answer\n",
    "def generate_answer_with_gemini(query, retrieved_chunks):\n",
    "    # Combine the retrieved chunks into a single context\n",
    "    context = \"\\n\".join(retrieved_chunks)\n",
    "\n",
    "    # Crafting the prompt for PhysioBot\n",
    "    prompt = f\"\"\"\n",
    "    You are a PhysioBOT and you have been asked to provide information from the sources you have read : {context}\n",
    "    A user asks you: \"{query}\"\n",
    "    you must answer in a very friendly and informative way \n",
    "    Based on your knowledge, you provide the following answer:\n",
    "    \"\"\"\n",
    "\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    response = model.generate_content([prompt])\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Embedding the query...\n",
      "Step 1 complete.\n",
      "Step 2: Retrieving relevant chunks from Pinecone...\n",
      "Step 2 complete.\n",
      "Step 3: Generating an answer using Gemini Pro LLM...\n",
      "Step 3 complete.\n",
      "\n",
      "Physio-BOT's Answer:\n",
      "**Possible Reasons for Back Pain**\n",
      "\n",
      "Back pain is a common condition that can have a variety of causes. Some of the most common causes include:\n",
      "\n",
      "* **Muscle strain or sprain:** This is the most common cause of back pain. It can occur when you lift something heavy incorrectly, twist your back awkwardly, or overuse your back muscles.\n",
      "* **Herniated disc:** This occurs when the soft, jelly-like center of an intervertebral disc pushes through the tough outer layer of the disc. This can put pressure on the nerves in your spinal cord, causing pain, numbness, and weakness.\n",
      "* **Sciatica:** This is a type of back pain that radiates down the sciatic nerve, which runs from your lower back through your buttocks and down the back of your leg. It can be caused by a herniated disc, spinal stenosis, or other conditions that put pressure on the sciatic nerve.\n",
      "* **Spinal stenosis:** This is a condition in which the spinal canal, which is the space through which the spinal cord passes, becomes narrowed. This can put pressure on the spinal cord and nerves, causing pain, numbness, and weakness.\n",
      "* **Osteoarthritis:** This is a type of arthritis that causes the cartilage in your joints to break down. It can occur in the spine, causing back pain, stiffness, and loss of range of motion.\n",
      "* **Other medical conditions:** Back pain can also be a symptom of other medical conditions, such as kidney stones, infections, or cancer.\n",
      "\n",
      "If you are experiencing back pain, it is important to see a doctor or physiotherapist to get an accurate diagnosis and treatment plan.\n"
     ]
    }
   ],
   "source": [
    "# Main function to handle user input and process the query through Physio-BOT\n",
    "def main():\n",
    "    # Prompt user for input\n",
    "    query = input(\"What would you like to ask Physio-BOT? \")\n",
    "\n",
    "    print(\"Step 1: Embedding the query...\")\n",
    "    # Step 1: Embed the query using Gemini Pro\n",
    "    query_embedding = generate_query_embedding(query)\n",
    "    print(\"Step 1 complete.\")\n",
    "\n",
    "    print(\"Step 2: Retrieving relevant chunks from Pinecone...\")\n",
    "    # Step 2: Retrieve relevant chunks from Pinecone based on query embedding\n",
    "    retrieved_chunks = retrieve_relevant_chunks(query_embedding)\n",
    "    print(\"Step 2 complete.\")\n",
    "\n",
    "    print(\"Step 3: Generating an answer using Gemini Pro LLM...\")\n",
    "    # Step 3: Generate an answer using Gemini Pro LLM with the retrieved chunks\n",
    "    answer = generate_answer_with_gemini(query, retrieved_chunks)\n",
    "    print(\"Step 3 complete.\")\n",
    "\n",
    "\n",
    "    # Display the final answer to the user\n",
    "    print(\"\\nPhysio-BOT's Answer:\")\n",
    "    print(answer)\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "physioenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
